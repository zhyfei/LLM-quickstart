{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODgmrhkYCwOl",
    "outputId": "b61fa7c7-205f-4e77-abb0-09b2047c94ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100% 7/7 [00:04<00:00,  1.49it/s]\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "2024-04-01 14:36:31.730065: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 14:36:31.730126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 14:36:31.731571: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 14:36:32.986944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "碎花裙子的款式和颜色有很多种,有深色调的,也有浅色调的,还有花纹比较密集的,也有比较简约的,比较大气。花纹比较密集的碎花裙子的花纹比较密集,比较有层次感,比较有气质。比较简约大气,比较优雅大气。比较气质大气,比较大气大气。比较气质大气,比较气质大气气质。比较气质大气,比较气质大气气质气质比较气质大气。\n"
     ]
    }
   ],
   "source": [
    "!python inference_hf.py /content/drive/MyDrive/finetune_demo/output/checkpoint-12000 --prompt \"碎花裙子\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-YeUUMIC6p5",
    "outputId": "aa6c2444-d4fa-4a05-e45a-f2ce94b775fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100% 7/7 [00:04<00:00,  1.51it/s]\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "2024-04-01 14:36:48.853041: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-01 14:36:48.853110: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-01 14:36:48.854529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-01 14:36:50.153184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "简约的英伦风，经典的基础款式，百搭耐看，简约大气，不显沉闷。简约的款式，简约而不简单，简洁大方，穿着舒适。软软的布料，柔软亲肤，手感舒适，穿着不闷热。\n"
     ]
    }
   ],
   "source": [
    "!python inference_hf.py /content/drive/MyDrive/finetune_demo/output/checkpoint-12000 --prompt \"类型#裤*风格#英伦*风格#简约\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805,
     "referenced_widgets": [
      "9a020074ed9f4fd5979fe757c3bb257d",
      "0afe73d06bb443618fd3f9158435cea7",
      "86256701feca4439a7ea152bd797c2fa",
      "6eb2b7deacb74d4db4e48faa7f041e99",
      "9aa7618db80b4ddc932eec7850f9f8ef",
      "a32e8e65ee524abea27aec729048330e",
      "4f8b340d4bf74d319182773c97944301",
      "cab159b09f60422cb9d36651ec385adf",
      "0852f8e39fb641839cb67d9bbb1c7655",
      "c27a852c21ef4630a49dc536610ce27a",
      "84614963355546dd953b75c7911762a6"
     ]
    },
    "id": "rvr73pJmDmXj",
    "outputId": "0fd196b5-3e69-46b9-d7b0-186bcbe18aab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a020074ed9f4fd5979fe757c3bb257d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting eos_token is not supported, use the default one.\n",
      "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting pad_token is not supported, use the default one.\n",
      "WARNING:transformers_modules.THUDM.chatglm3-6b.a5ba5501eb873d40d48bd0983bd2a8dd006bb838.tokenization_chatglm:Setting unk_token is not supported, use the default one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://53db651ea0ecda49ee.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://53db651ea0ecda49ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import torch\n",
    "from threading import Thread\n",
    "\n",
    "from typing import Union, Annotated\n",
    "from pathlib import Path\n",
    "from peft import AutoPeftModelForCausalLM, PeftModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    PreTrainedTokenizerFast,\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    TextIteratorStreamer\n",
    ")\n",
    "\n",
    "ModelType = Union[PreTrainedModel, PeftModelForCausalLM]\n",
    "TokenizerType = Union[PreTrainedTokenizer, PreTrainedTokenizerFast]\n",
    "\n",
    "MODEL_PATH = '/content/drive/MyDrive/finetune_demo/output/checkpoint-12000'\n",
    "TOKENIZER_PATH = MODEL_PATH\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(\n",
    "        model_dir: Union[str, Path], trust_remote_code: bool = True\n",
    ") -> tuple[ModelType, TokenizerType]:\n",
    "    model_dir = _resolve_path(model_dir)\n",
    "    if (model_dir / 'adapter_config.json').exists():\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            model_dir, trust_remote_code=trust_remote_code, device_map='auto'\n",
    "        )\n",
    "        tokenizer_dir = model.peft_config['default'].base_model_name_or_path\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_dir, trust_remote_code=trust_remote_code, device_map='auto'\n",
    "        )\n",
    "        tokenizer_dir = model_dir\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_dir, trust_remote_code=trust_remote_code\n",
    "    )\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [0, 2]\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def parse_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if line != \"\"]\n",
    "    count = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"```\" in line:\n",
    "            count += 1\n",
    "            items = line.split('`')\n",
    "            if count % 2 == 1:\n",
    "                lines[i] = f'<pre><code class=\"language-{items[-1]}\">'\n",
    "            else:\n",
    "                lines[i] = f'<br></code></pre>'\n",
    "        else:\n",
    "            if i > 0:\n",
    "                if count % 2 == 1:\n",
    "                    line = line.replace(\"`\", \"\\`\")\n",
    "                    line = line.replace(\"<\", \"&lt;\")\n",
    "                    line = line.replace(\">\", \"&gt;\")\n",
    "                    line = line.replace(\" \", \"&nbsp;\")\n",
    "                    line = line.replace(\"*\", \"&ast;\")\n",
    "                    line = line.replace(\"_\", \"&lowbar;\")\n",
    "                    line = line.replace(\"-\", \"&#45;\")\n",
    "                    line = line.replace(\".\", \"&#46;\")\n",
    "                    line = line.replace(\"!\", \"&#33;\")\n",
    "                    line = line.replace(\"(\", \"&#40;\")\n",
    "                    line = line.replace(\")\", \"&#41;\")\n",
    "                    line = line.replace(\"$\", \"&#36;\")\n",
    "                lines[i] = \"<br>\" + line\n",
    "    text = \"\".join(lines)\n",
    "    return text\n",
    "\n",
    "\n",
    "def predict(history, max_length, top_p, temperature):\n",
    "    stop = StopOnTokens()\n",
    "    messages = []\n",
    "    for idx, (user_msg, model_msg) in enumerate(history):\n",
    "        if idx == len(history) - 1 and not model_msg:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            break\n",
    "        if user_msg:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        if model_msg:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": model_msg})\n",
    "\n",
    "    print(\"\\n\\n====conversation====\\n\", messages)\n",
    "    model_inputs = tokenizer.apply_chat_template(messages,\n",
    "                                                 add_generation_prompt=True,\n",
    "                                                 tokenize=True,\n",
    "                                                 return_tensors=\"pt\").to(next(model.parameters()).device)\n",
    "    streamer = TextIteratorStreamer(tokenizer, timeout=60, skip_prompt=True, skip_special_tokens=True)\n",
    "    generate_kwargs = {\n",
    "        \"input_ids\": model_inputs,\n",
    "        \"streamer\": streamer,\n",
    "        \"max_new_tokens\": max_length,\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": top_p,\n",
    "        \"temperature\": temperature,\n",
    "        \"stopping_criteria\": StoppingCriteriaList([stop]),\n",
    "        \"repetition_penalty\": 1.2,\n",
    "    }\n",
    "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
    "    t.start()\n",
    "\n",
    "    for new_token in streamer:\n",
    "        if new_token != '':\n",
    "            history[-1][1] += new_token\n",
    "            yield history\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.HTML(\"\"\"<h1 align=\"center\">ChatGLM3-6B Gradio Simple Demo</h1>\"\"\")\n",
    "    chatbot = gr.Chatbot()\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            with gr.Column(scale=12):\n",
    "                user_input = gr.Textbox(show_label=False, placeholder=\"Input...\", lines=10, container=False)\n",
    "            with gr.Column(min_width=32, scale=1):\n",
    "                submitBtn = gr.Button(\"Submit\")\n",
    "        with gr.Column(scale=1):\n",
    "            emptyBtn = gr.Button(\"Clear History\")\n",
    "            max_length = gr.Slider(0, 32768, value=8192, step=1.0, label=\"Maximum length\", interactive=True)\n",
    "            top_p = gr.Slider(0, 1, value=0.8, step=0.01, label=\"Top P\", interactive=True)\n",
    "            temperature = gr.Slider(0.01, 1, value=0.6, step=0.01, label=\"Temperature\", interactive=True)\n",
    "\n",
    "\n",
    "    def user(query, history):\n",
    "        return \"\", history + [[parse_text(query), \"\"]]\n",
    "\n",
    "\n",
    "    submitBtn.click(user, [user_input, chatbot], [user_input, chatbot], queue=False).then(\n",
    "        predict, [chatbot, max_length, top_p, temperature], chatbot\n",
    "    )\n",
    "    emptyBtn.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0852f8e39fb641839cb67d9bbb1c7655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0afe73d06bb443618fd3f9158435cea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a32e8e65ee524abea27aec729048330e",
      "placeholder": "​",
      "style": "IPY_MODEL_4f8b340d4bf74d319182773c97944301",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "4f8b340d4bf74d319182773c97944301": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6eb2b7deacb74d4db4e48faa7f041e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c27a852c21ef4630a49dc536610ce27a",
      "placeholder": "​",
      "style": "IPY_MODEL_84614963355546dd953b75c7911762a6",
      "value": " 7/7 [00:05&lt;00:00,  1.43it/s]"
     }
    },
    "84614963355546dd953b75c7911762a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86256701feca4439a7ea152bd797c2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cab159b09f60422cb9d36651ec385adf",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0852f8e39fb641839cb67d9bbb1c7655",
      "value": 7
     }
    },
    "9a020074ed9f4fd5979fe757c3bb257d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0afe73d06bb443618fd3f9158435cea7",
       "IPY_MODEL_86256701feca4439a7ea152bd797c2fa",
       "IPY_MODEL_6eb2b7deacb74d4db4e48faa7f041e99"
      ],
      "layout": "IPY_MODEL_9aa7618db80b4ddc932eec7850f9f8ef"
     }
    },
    "9aa7618db80b4ddc932eec7850f9f8ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32e8e65ee524abea27aec729048330e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c27a852c21ef4630a49dc536610ce27a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cab159b09f60422cb9d36651ec385adf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
